{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                                wrangle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Introduction \n",
    "This project focused on the Data wrangling, by fixing the data Quality and Tidness issues by using Python\n",
    "\n",
    "### Data Gathering\n",
    " The first step is to gather the data from 3 files.\n",
    " 1. (twitter_archive_enhanced.csv) the WeRateDogs Twitter archive which is provided by the Udacity. and I have import it bu using pd.read_csv()\n",
    " \n",
    " 2. (image_predictions.tsv) The tweet image predictions, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. This file is hosted on Udacity's servers and should be downloaded programmatically using the Requests library and the following URL.\n",
    " \n",
    " 3. (tweet_json.txt) Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file. Each tweet's JSON data should be written to its own line. \n",
    "\n",
    "\n",
    "### Data Assessing\n",
    " For the Data Assessing, there are 2 parts: Quality and Tidness issues. to further explain\n",
    " \n",
    "* Quality issues related to the content of the data such as duplicates, missing, incorrect data.\n",
    "* Tidness issues which is structural issues\n",
    " \n",
    "### Quality issues \n",
    "\n",
    "##### For twitter_archive dataset \n",
    "\n",
    "\n",
    "1. Dogs names are not correct there are names like 'a', 'this' and 'none' \n",
    "\n",
    "2. since the tweet id will not be used in the calculation it should be a string rather than integer\n",
    "\n",
    "3.  timestamp data type should be DateTime instead \n",
    "\n",
    "4. Capitalize the first letter in the name of dogs\n",
    "\n",
    "5.  source instead of links make it in words \n",
    "\n",
    "6. Drop useless columns \n",
    "\n",
    "\n",
    "##### For image_predictions\n",
    "\n",
    "7. the columns name 'p1', 'p2', 'p3' \n",
    "\n",
    "##### For json_tweet\n",
    "\n",
    "8. the favorites and retweets columns should be converted to int datatype \n",
    "\n",
    "### Tidness issues\n",
    "\n",
    "1. the doge types are in separated columns we have to merge it in one column called dog_types \n",
    "\n",
    "2. matching the data in twitter_archive dataset and tweet-JSON because the data is sorted in separated tables\n",
    "\n",
    "### Data cleaning\n",
    "\n",
    "##### Before the cleaning I have to take a copy for each file\n",
    "\n",
    "#### Tidness issues\n",
    "1. merge json_tweet and image_predictions into twitter_archive by inner join\n",
    "2. I have create a new column with name dog_types and that containing the 4 dog types, then drop the 4 columns.\n",
    "\n",
    "### Quality issues \n",
    "\n",
    "1. change the 'timestamp' datatype to DateTime so it becomes a year, month, day\n",
    "\n",
    "2. change the tweet id in (twitter_archive_enhanced) to string after we merge all the files\n",
    "\n",
    "3. correct the dog's names by counting them and after that see what the incorrect names. After that, I use a list that contains the incorrect name and replace it with none\n",
    "\n",
    "4. make all the first letter in the 'name' Capitalize\n",
    "\n",
    "5. Change the source instead of links to words to be more readable. first, I count the values, then I replace the links with the words of the source\n",
    "\n",
    "6. i have dropped the useless columns (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp) because it have a large number of missing values \n",
    "\n",
    "7. I have covert the datatype of favorites and retweets so I can use it.\n",
    "\n",
    "8. Change the columns name for to make it readable 'p1', 'p2', 'p3' , 'p1_conf', 'p2_conf' and 'p3_conf' by using 'rename' \n",
    "\n",
    "\n",
    "* final step is I have store the clean DataFrame(s) in a CSV file with the main one named (twitter_archive_master.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
